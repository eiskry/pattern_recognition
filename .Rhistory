activation_model <- keras_model(inputs = model$input, outputs = layer_outputs)
hist(wgts[[1]], breaks=seq(-3,5,0.2), freq=TRUE)
##################### 素子出力の観測
######## モデルの各層の出力の観測
layer_outputs <- lapply(model$layers, function(layer) layer$output)
model$layers
layer_outputs
######## ある入力に対する出力を計算するモデルを定義する
activation_model <- keras_model(inputs = model$input, outputs = layer_outputs)
model$input
activation_model
######## 入力データを用意する
test <- array_reshape(test.data[1, ], c(1,4))
######## 入力に対する各層の素子の出力を計算する
activations <- activation_model %>% predict(test)
activations
first_layer_activation <- activations[[1]]
barplot(first_layer_activation, names=1:8)
test.data
sv
##################### パッケージインストール
library(keras)
library(MASS)
##################### データの準備
sv <- rbind(iris3[,,1], iris3[,,3]) # setosa+virginica
vc <- iris3[,,2] # versicolor
svcl <- c(rep(1,100)) # sv のクラスを1
sv <- cbind(sv,svcl)
vccl <- c(rep(0,50)) # vc のクラスを0
vc <- cbind(vc, vccl)
sv
######## モデルオブジェクトの準備
model <- keras_model_sequential()
######## model内部の構造の構築
model %>%
layer_dense( units = 16, activation = 'sigmoid', input_shape = c(4) ) %>%
layer_dense( units = 1, activation = 'sigmoid' )
model %>%
layer_dense( units = 16, activation = 'sigmoid', input_shape = c(4), kernel_regularizer = regularizer_l2(0.001) ) %>%
layer_dense( units = 1, activation = 'sigmoid', kernel_regularizer = regularizer_l2(0.001) )
######## modelのコンパイル
model %>%
compile(loss = 'binary_crossentropy',  # 2クラス問題→2値クロスエントロピー
optimizer = optimizer_sgd(lr = 0.05),
metrics = c('accuracy')
)
######## model内部の構造の構築
model %>%
layer_dense( units = 16, activation = 'sigmoid', input_shape = c(4) ) %>%
layer_dense( units = 1, activation = 'sigmoid' )
######## modelのコンパイル
model %>%
compile(loss = 'binary_crossentropy',  # 2クラス問題→2値クロスエントロピー
optimizer = optimizer_sgd(lr = 0.05),
metrics = c('accuracy')
)
######## モデルの実行
history <- model %>% fit(
train.data,
train.targets,
epochs = 500,
batch_size = 5,
validation_split = 0.2
)
##################### パッケージインストール
library(keras)
library(MASS)
##################### データの準備
sv <- rbind(iris3[,,1], iris3[,,3]) # setosa+virginica
##################### パッケージインストール
library(keras)
library(MASS)
##################### データの準備
sv <- rbind(iris3[,,1], iris3[,,3]) # setosa+virginica
vc <- iris3[,,2] # versicolor
svcl <- c(rep(1,100)) # sv のクラスを1
sv <- cbind(sv,svcl)
vccl <- c(rep(0,50)) # vc のクラスを0
vc <- cbind(vc, vccl)
sv <- as.matrix(sv) # 行列に変換
vc <- as.matrix(vc)
colnames(sv) <- NULL # 列名を削除
colnames(vc) <- NULL
svc <- rbind(sv, vc)
ind <- sample(1:nrow(svc), nrow(svc)*2/3) # 全体の2/3を学習データに
train.data <- svc[ind, 1:4]
test.data <- svc[-ind, 1:4] # 残りの1/3をテストデータに
train.targets <- svc[ind, 5]
test.targets <- svc[-ind, 5]
######## モデルオブジェクトの準備
model <- keras_model_sequential()
######## model内部の構造の構築
model %>%
layer_dense( units = 16, activation = 'sigmoid', input_shape = c(4) ) %>%
layer_dense( units = 1, activation = 'sigmoid' )
######## modelのコンパイル
model %>%
compile(loss = 'binary_crossentropy',  # 2クラス問題→2値クロスエントロピー
optimizer = optimizer_sgd(lr = 0.05),
metrics = c('accuracy')
)
######## モデルの実行
history <- model %>% fit(
train.data,
train.targets,
epochs = 500,
batch_size = 5,
validation_split = 0.2
)
######## model内部の構造の構築
model %>%
layer_dense( units = 16, activation = 'sigmoid', input_shape = c(4) ) %>%
layer_dense( units = 1, activation = 'sigmoid' )
######## modelのコンパイル
model %>%
compile(loss = 'binary_crossentropy',  # 2クラス問題→2値クロスエントロピー
optimizer = optimizer_sgd(lr = 0.05),
metrics = c('accuracy')
)
######## モデルの実行
history <- model %>% fit(
train.data,
train.targets,
epochs = 500,
batch_size = 5,
validation_split = 0.2
)
##################### パッケージインストール
library(keras)
library(MASS)
##################### データの準備
sv <- rbind(iris3[,,1], iris3[,,3]) # setosa+virginica
vc <- iris3[,,2] # versicolor
svcl <- c(rep(1,100)) # sv のクラスを1
sv <- cbind(sv,svcl)
vccl <- c(rep(0,50)) # vc のクラスを0
vc <- cbind(vc, vccl)
sv <- as.matrix(sv) # 行列に変換
vc <- as.matrix(vc)
colnames(sv) <- NULL # 列名を削除
colnames(vc) <- NULL
svc <- rbind(sv, vc)
ind <- sample(1:nrow(svc), nrow(svc)*2/3) # 全体の2/3を学習データに
train.data <- svc[ind, 1:4]
test.data <- svc[-ind, 1:4] # 残りの1/3をテストデータに
train.targets <- svc[ind, 5]
test.targets <- svc[-ind, 5]
######## モデルオブジェクトの準備
model <- keras_model_sequential()
######## model内部の構造の構築
model %>%
layer_dense( units = 16, activation = 'sigmoid', input_shape = c(4) ) %>%
layer_dense( units = 1, activation = 'sigmoid' )
######## modelのコンパイル
model %>%
compile(loss = 'binary_crossentropy',  # 2クラス問題→2値クロスエントロピー
optimizer = optimizer_sgd(lr = 0.05),
metrics = c('accuracy')
)
######## モデルの実行
history <- model %>% fit(
train.data,
train.targets,
epochs = 500,
batch_size = 5,
validation_split = 0.2
)
######## テストデータによる汎化誤差の評価
score <- model %>% evaluate(test.data, test.targets, batch_size=128)
print(score)
######## モデルオブジェクトの準備
model <- keras_model_sequential()
######## model内部の構造の構築
model %>%
layer_dense( units = 8, activation = 'sigmoid', input_shape = c(4) ) %>%
layer_dense( units = 1, activation = 'sigmoid' )
######## modelのコンパイル
model %>%
compile(loss = 'binary_crossentropy',  # 2クラス問題→2値クロスエントロピー
optimizer = optimizer_sgd(lr = 0.05),
metrics = c('accuracy')
)
######## モデルの実行
history <- model %>% fit(
train.data,
train.targets,
epochs = 500,
batch_size = 5,
validation_split = 0.2
)
######## モデルオブジェクトの準備
model <- keras_model_sequential()
######## model内部の構造の構築
model %>%
layer_dense( units = 16, activation = 'sigmoid', input_shape = c(4) ) %>%
layer_dense( units = 1, activation = 'sigmoid' )
######## modelのコンパイル
model %>%
compile(loss = 'binary_crossentropy',  # 2クラス問題→2値クロスエントロピー
optimizer = optimizer_sgd(lr = 0.05),
metrics = c('accuracy')
)
######## モデルの実行
history <- model %>% fit(
train.data,
train.targets,
epochs = 500,
batch_size = 5,
validation_split = 0.2
)
##################### パッケージインストール
library(keras)
library(MASS)
##################### データの準備
sv <- rbind(iris3[,,1], iris3[,,3]) # setosa+virginica
vc <- iris3[,,2] # versicolor
svcl <- c(rep(1,100)) # sv のクラスを1
sv <- cbind(sv,svcl)
vccl <- c(rep(0,50)) # vc のクラスを0
vc <- cbind(vc, vccl)
sv <- as.matrix(sv) # 行列に変換
vc <- as.matrix(vc)
colnames(sv) <- NULL # 列名を削除
colnames(vc) <- NULL
svc <- rbind(sv, vc)
ind <- sample(1:nrow(svc), nrow(svc)*2/3) # 全体の2/3を学習データに
train.data <- svc[ind, 1:4]
test.data <- svc[-ind, 1:4] # 残りの1/3をテストデータに
train.targets <- svc[ind, 5]
test.targets <- svc[-ind, 5]
######## モデルオブジェクトの準備
model <- keras_model_sequential()
######## model内部の構造の構築
model %>%
layer_dense( units = 16, activation = 'sigmoid', input_shape = c(4) ) %>%
layer_dense( units = 1, activation = 'sigmoid' )
######## modelのコンパイル
model %>%
compile(loss = 'binary_crossentropy',  # 2クラス問題→2値クロスエントロピー
optimizer = optimizer_sgd(lr = 0.05),
metrics = c('accuracy')
)
######## モデルの実行
history <- model %>% fit(
train.data,
train.targets,
epochs = 500,
batch_size = 5,
validation_split = 0.2
)
######## テストデータによる汎化誤差の評価
score <- model %>% evaluate(test.data, test.targets, batch_size=128)
print(score)
## テストデータに対してモデルが識別したクラスを得る
classes <- model %>% predict_classes(test.data, batch_size = 128)
test.targets
classes
table(test.targets,classes)
wgts <- get_weights(model)
wgts
hist(wgts[[1]], breaks=seq(-3,5,0.2), freq=TRUE)
test.data
hist(wgts[[1]], breaks=seq(-3,5,0.2), freq=TRUE)
wgts <- get_weights(model)
wgts
hist(wgts[[1]], breaks=seq(-3,5,0.2), freq=TRUE)
hist(wgts[[1]], breaks=seq(-3,5,0.2), freq=TRUE)
hist(wgts[[1]], breaks=seq(-3,5,0.2), freq=TRUE)
wgts
hist(wgts[[1]], breaks=seq(-4,6,0.2), freq=TRUE)
hist(wgts[[1]], breaks=seq(-4,4,0.2), freq=TRUE)
######## モデルオブジェクトの準備
model <- keras_model_sequential()
model %>%
layer_dense( units = 16, activation = 'sigmoid', input_shape = c(4), kernel_regularizer = regularizer_l2(0.001) ) %>%
layer_dense( units = 1, activation = 'sigmoid', kernel_regularizer = regularizer_l2(0.001) )
######## modelのコンパイル
model %>%
compile(loss = 'binary_crossentropy',  # 2クラス問題→2値クロスエントロピー
optimizer = optimizer_sgd(lr = 0.05),
metrics = c('accuracy')
)
######## モデルの実行
history <- model %>% fit(
train.data,
train.targets,
epochs = 500,
batch_size = 5,
validation_split = 0.2
)
######## テストデータによる汎化誤差の評価
score <- model %>% evaluate(test.data, test.targets, batch_size=128)
print(score)
## テストデータに対してモデルが識別したクラスを得る
classes <- model %>% predict_classes(test.data, batch_size = 128)
test.targets
classes
table(test.targets,classes)
wgts <- get_weights(model)
wgts
hist(wgts[[1]], breaks=seq(-4,4,0.2), freq=TRUE)
_
######## model内部の構造の構築
model %>%
layer_dense( units = 16, activation = 'sigmoid', input_shape = c(4) ) %>%
layer_dense( units = 1, activation = 'sigmoid' )
######## モデルオブジェクトの準備
model <- keras_model_sequential()
######## model内部の構造の構築
model %>%
layer_dense( units = 16, activation = 'sigmoid', input_shape = c(4) ) %>%
layer_dense( units = 1, activation = 'sigmoid' )
######## modelのコンパイル
model %>%
compile(loss = 'binary_crossentropy',  # 2クラス問題→2値クロスエントロピー
optimizer = optimizer_sgd(lr = 0.05),
metrics = c('accuracy')
)
######## モデルの実行
history <- model %>% fit(
train.data,
train.targets,
epochs = 500,
batch_size = 5,
validation_split = 0.2
)
######## テストデータによる汎化誤差の評価
score <- model %>% evaluate(test.data, test.targets, batch_size=128)
print(score)
## テストデータに対してモデルが識別したクラスを得る
classes <- model %>% predict_classes(test.data, batch_size = 128)
test.targets
classes
table(test.targets,classes)
wgts <- get_weights(model)
wgts
hist(wgts[[1]], breaks=seq(-4,4,0.2), freq=TRUE)
test.data
##################### 素子出力の観測
######## モデルの各層の出力の観測
layer_outputs <- lapply(model$layers, function(layer) layer$output)
model$layers
layer_outputs
######## ある入力に対する出力を計算するモデルを定義する
activation_model <- keras_model(inputs = model$input, outputs = layer_outputs)
model$input
activation_model
######## 入力データを用意する
test <- array_reshape(test.data[1, ], c(1,4))
######## 入力に対する各層の素子の出力を計算する
activations <- activation_model %>% predict(test)
activations
first_layer_activation <- activations[[1]]
barplot(first_layer_activation, names=1:8)
barplot(first_layer_activation, names=1:16)
test.data
test
ind
test.targets
train.data
test.data
train.targets
test.targets
test.targets
######## 入力データを用意する
test <- array_reshape(test.data[50, ], c(1,4))
test
######## 入力に対する各層の素子の出力を計算する
activations <- activation_model %>% predict(test)
activations
first_layer_activation <- activations[[1]]
barplot(first_layer_activation, names=1:16)
######## モデルオブジェクトの準備
model <- keras_model_sequential()
######## model内部の構造の構築
model %>%
layer_dense( units = 16, activation = 'sigmoid', input_shape = c(4) ) %>%
layer_dense( units = 1, activation = 'sigmoid' )
model %>%
layer_dense( units = 16, activation = 'sigmoid', input_shape = c(4), kernel_regularizer = regularizer_l2(0.001) ) %>%
layer_dense( units = 1, activation = 'sigmoid', kernel_regularizer = regularizer_l2(0.001) )
######## modelのコンパイル
model %>%
compile(loss = 'binary_crossentropy',  # 2クラス問題→2値クロスエントロピー
optimizer = optimizer_sgd(lr = 0.05),
metrics = c('accuracy')
)
######## モデルの実行
history <- model %>% fit(
train.data,
train.targets,
epochs = 500,
batch_size = 5,
validation_split = 0.2
)
##################### パッケージインストール
library(keras)
library(MASS)
##################### データの準備
sv <- rbind(iris3[,,1], iris3[,,3]) # setosa+virginica
vc <- iris3[,,2] # versicolor
svcl <- c(rep(1,100)) # sv のクラスを1
sv <- cbind(sv,svcl)
vccl <- c(rep(0,50)) # vc のクラスを0
vc <- cbind(vc, vccl)
sv <- as.matrix(sv) # 行列に変換
vc <- as.matrix(vc)
colnames(sv) <- NULL # 列名を削除
colnames(vc) <- NULL
svc <- rbind(sv, vc)
ind <- sample(1:nrow(svc), nrow(svc)*2/3) # 全体の2/3を学習データに
train.data <- svc[ind, 1:4]
train.data
test.data <- svc[-ind, 1:4] # 残りの1/3をテストデータに
test.data
train.targets <- svc[ind, 5]
train.targets
test.targets <- svc[-ind, 5]
test.targets
######## モデルオブジェクトの準備
model <- keras_model_sequential()
model %>%
layer_dense( units = 16, activation = 'sigmoid', input_shape = c(4), kernel_regularizer = regularizer_l2(0.001) ) %>%
layer_dense( units = 1, activation = 'sigmoid', kernel_regularizer = regularizer_l2(0.001) )
######## modelのコンパイル
model %>%
compile(loss = 'binary_crossentropy',  # 2クラス問題→2値クロスエントロピー
optimizer = optimizer_sgd(lr = 0.05),
metrics = c('accuracy')
)
######## モデルの実行
history <- model %>% fit(
train.data,
train.targets,
epochs = 500,
batch_size = 5,
validation_split = 0.2
)
######## テストデータによる汎化誤差の評価
score <- model %>% evaluate(test.data, test.targets, batch_size=128)
print(score)
## テストデータに対してモデルが識別したクラスを得る
classes <- model %>% predict_classes(test.data, batch_size = 128)
test.targets
classes
table(test.targets,classes)
wgts <- get_weights(model)
wgts
hist(wgts[[1]], breaks=seq(-4,4,0.2), freq=TRUE)
test.data
hist(wgts[[1]], breaks=seq(-40,40,0.2), freq=TRUE)
hist(wgts[[1]], breaks=seq(-4,4,0.2), freq=TRUE)
##################### パッケージインストール
library(keras)
library(MASS)
##################### データの準備
sv <- rbind(iris3[,,1], iris3[,,3]) # setosa+virginica
vc <- iris3[,,2] # versicolor
svcl <- c(rep(1,100)) # sv のクラスを1
sv <- cbind(sv,svcl)
vccl <- c(rep(0,50)) # vc のクラスを0
vc <- cbind(vc, vccl)
sv <- as.matrix(sv) # 行列に変換
vc <- as.matrix(vc)
colnames(sv) <- NULL # 列名を削除
colnames(vc) <- NULL
svc <- rbind(sv, vc)
ind <- sample(1:nrow(svc), nrow(svc)*2/3) # 全体の2/3を学習データに
train.data <- svc[ind, 1:4]
train.data
test.data <- svc[-ind, 1:4] # 残りの1/3をテストデータに
test.data
train.targets <- svc[ind, 5]
train.targets
test.targets <- svc[-ind, 5]
test.targets
######## モデルオブジェクトの準備
model <- keras_model_sequential()
######## model内部の構造の構築
model %>%
layer_dense( units = 16, activation = 'sigmoid', input_shape = c(4) ) %>%
layer_dense( units = 1, activation = 'sigmoid' )
######## modelのコンパイル
model %>%
compile(loss = 'binary_crossentropy',  # 2クラス問題→2値クロスエントロピー
optimizer = optimizer_sgd(lr = 0.05),
metrics = c('accuracy')
)
######## モデルの実行
history <- model %>% fit(
train.data,
train.targets,
epochs = 500,
batch_size = 5,
validation_split = 0.2
)
######## テストデータによる汎化誤差の評価
score <- model %>% evaluate(test.data, test.targets, batch_size=128)
print(score)
## テストデータに対してモデルが識別したクラスを得る
classes <- model %>% predict_classes(test.data, batch_size = 128)
test.targets
classes
table(test.targets,classes)
wgts <- get_weights(model)
wgts
hist(wgts[[1]], breaks=seq(-4,4,0.2), freq=TRUE)
test.data
hist(wgts[[1]], breaks=seq(-40,40,0.2), freq=TRUE)
hist(wgts[[1]], breaks=seq(-4,4,0.2), freq=TRUE)
hist(wgts[[1]], breaks=seq(-10,10,0.2), freq=TRUE)
hist(wgts[[1]], breaks=seq(-4,4,0.2), freq=TRUE)
